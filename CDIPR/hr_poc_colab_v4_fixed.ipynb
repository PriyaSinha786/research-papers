{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyaSinha786/research-papers/blob/main/CDIPR/hr_poc_colab_v4_fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b591ad",
      "metadata": {
        "id": "89b591ad"
      },
      "source": [
        "# HR Governance POC v4 — Colab Notebook (Fixed OpenAI & HF issues)\n",
        "\n",
        "This fixed notebook includes:\n",
        "- pinned `huggingface_hub` to avoid `cached_download` import error\n",
        "- upgraded `openai` client usage to the modern `OpenAI` class for embeddings\n",
        "- diagnostic cells to check for name collisions\n",
        "\n",
        "**Run cells in order.** If you changed packages, restart the runtime (Runtime → Restart runtime) before running the index cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1ee4cd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ee4cd7",
        "outputId": "9fc31df6-e9c6-4b97-eb48-4a56a291c36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.44.1 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.25.2 which is incompatible.\n",
            "transformers 4.56.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 0.25.2 which is incompatible.\n",
            "diffusers 0.35.1 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mInstalled / upgraded packages. IMPORTANT: If this changed packages, restart the runtime (Runtime -> Restart runtime) and re-run the notebook cells from the start.)\n"
          ]
        }
      ],
      "source": [
        "# Install and pin packages that are known to work together\n",
        "# This pins huggingface_hub to a compatible version for sentence-transformers 2.2.2\n",
        "!pip install --upgrade --quiet openai\n",
        "!pip install --upgrade --quiet sentence-transformers==2.2.2\n",
        "!pip install --upgrade --quiet \"huggingface_hub==0.25.2\"\n",
        "!pip install --upgrade --quiet scikit-learn pandas joblib networkx matplotlib\n",
        "print('Installed / upgraded packages. IMPORTANT: If this changed packages, restart the runtime (Runtime -> Restart runtime) and re-run the notebook cells from the start.)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "50ed60cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ed60cf",
        "outputId": "6a65c3ae-3a5b-4ba0-d061-78605302ce3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /content\n",
            "Files here: ['.config', 'sample_data']\n",
            "\n",
            "openai module: <module 'openai' from '/usr/local/lib/python3.12/dist-packages/openai/__init__.py'>\n",
            "openai __file__: /usr/local/lib/python3.12/dist-packages/openai/__init__.py\n",
            "\n",
            "Select attributes containing \"emb\" or \"Emb\": ['Embedding', 'embeddings']\n",
            "\n",
            "sentence-transformers / huggingface_hub import issue: huggingface-hub>=0.34.0,<1.0 is required for a normal functioning of this module, but found huggingface-hub==0.25.2.\n",
            "Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\n",
            "\n",
            "If you see openai pointing to a local file (e.g. /content/openai.py), rename or remove that file and re-run this cell.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Diagnostic checks for common problems (name shadowing or missing attributes)\n",
        "import os, sys\n",
        "print('Working directory:', os.getcwd())\n",
        "print('Files here:', [f for f in os.listdir('.')][:50])\n",
        "\n",
        "try:\n",
        "    import openai\n",
        "    print('\\nopenai module:', openai)\n",
        "    print('openai __file__:', getattr(openai, '__file__', 'builtin or not file-backed'))\n",
        "    print('\\nSelect attributes containing \"emb\" or \"Emb\":', [k for k in dir(openai) if 'emb' in k.lower() or 'Emb' in k])\n",
        "except Exception as e:\n",
        "    print('Importing openai failed:', e)\n",
        "\n",
        "try:\n",
        "    import sentence_transformers, huggingface_hub\n",
        "    print('\\nsentence_transformers version OK, huggingface_hub path:', getattr(huggingface_hub, '__file__', None))\n",
        "except Exception as e:\n",
        "    print('\\nsentence-transformers / huggingface_hub import issue:', e)\n",
        "\n",
        "print('\\nIf you see openai pointing to a local file (e.g. /content/openai.py), rename or remove that file and re-run this cell.\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ab0a3bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0a3bc1",
        "outputId": "9a01c3c3-da11-4278-d7b1-31c963f5bb6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key (leave blank to skip): ··········\n",
            "OPENAI_API_KEY set (in environment).\n"
          ]
        }
      ],
      "source": [
        "# Set your OpenAI API key (optional). Use getpass so it isn't stored in clear text.\n",
        "from getpass import getpass\n",
        "import os\n",
        "key = getpass('Enter your OpenAI API key (leave blank to skip): ')\n",
        "if key:\n",
        "    os.environ['OPENAI_API_KEY'] = key\n",
        "    print('OPENAI_API_KEY set (in environment).')\n",
        "else:\n",
        "    print('No API key provided; the notebook will use local SBERT or TF-IDF fallback.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fc78fb5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc78fb5b",
        "outputId": "02da9e1f-1c1f-48e8-b660-230d545ab3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote attrition CSV to /content/hr_poc_openai/data/attrition_synthetic.csv\n",
            "Wrote resumes to /content/hr_poc_openai/data/resumes\n",
            "Wrote JDs to /content/hr_poc_openai/data/jds\n",
            "Wrote policies to /content/hr_poc_openai/data/policy_docs\n",
            "Wrote config.json\n"
          ]
        }
      ],
      "source": [
        "# Prepare synthetic data (resumes, jds, policies, attrition CSV)\n",
        "import os, random, json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "random.seed(42)\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "JDS = DATA / 'jds'\n",
        "POL = DATA / 'policy_docs'\n",
        "MODELS = BASE / 'models'\n",
        "OUT = BASE / 'output'\n",
        "for p in [DATA, RES, JDS, POL, MODELS, OUT]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Attrition CSV\n",
        "rows = []\n",
        "for i in range(500):\n",
        "    age = random.randint(22,60)\n",
        "    monthly_income = random.randint(2000,20000)\n",
        "    job_sat = random.choice([1,2,3,4])\n",
        "    years = random.randint(0,30)\n",
        "    gender = random.choice(['Male','Female'])\n",
        "    education = random.choice([1,2,3,4,5])\n",
        "    prob_attr = 0.2\n",
        "    if age < 30 and job_sat <= 2 and years < 3:\n",
        "        prob_attr = 0.6\n",
        "    attrition = 1 if random.random() < prob_attr else 0\n",
        "    rows.append([age, monthly_income, job_sat, years, gender, education, attrition])\n",
        "df = pd.DataFrame(rows, columns=['Age','MonthlyIncome','JobSatisfaction','YearsAtCompany','Gender','Education','Attrition'])\n",
        "df.to_csv(DATA/'attrition_synthetic.csv', index=False)\n",
        "print('Wrote attrition CSV to', DATA/'attrition_synthetic.csv')\n",
        "\n",
        "# Create resumes\n",
        "skills_pool = ['Python','Java','SQL','Machine Learning','Deep Learning','NLP','Computer Vision','Data Engineering','TensorFlow','PyTorch','Kubernetes','AWS','Docker','Communication','Leadership','UX Design','Figma','React','Sales','SEO','Google Analytics','Recruiting','Interviewing','Payroll','Testing']\n",
        "roles = ['Data Scientist','ML Engineer','Backend Developer','DevOps Engineer','Product Manager','QA Engineer','UX Designer','Sales Executive','Marketing Specialist','HR Specialist']\n",
        "for i in range(1,81):\n",
        "    name = f'Candidate_{i}'\n",
        "    role = roles[i % len(roles)]\n",
        "    if i % 8 == 0:\n",
        "        skills = random.sample([s for s in skills_pool if s not in ['Python','Machine Learning','SQL','TensorFlow','PyTorch']], k=random.randint(2,5))\n",
        "    else:\n",
        "        if 'Data' in role or 'ML' in role:\n",
        "            core = ['Python','SQL','Machine Learning','TensorFlow','PyTorch']\n",
        "        elif 'Backend' in role or 'DevOps' in role:\n",
        "            core = ['Java','Kubernetes','Docker','AWS','SQL']\n",
        "        elif 'Product' in role:\n",
        "            core = ['Communication','Leadership','React']\n",
        "        elif 'QA' in role:\n",
        "            core = ['Testing','Python','Java']\n",
        "        elif 'UX' in role:\n",
        "            core = ['UX Design','Figma','Communication']\n",
        "        elif 'Sales' in role or 'Marketing' in role:\n",
        "            core = ['Sales','SEO','Google Analytics','Communication']\n",
        "        elif 'HR' in role:\n",
        "            core = ['Recruiting','Interviewing','Payroll','Communication']\n",
        "        skills = list(set(random.sample(core, k=max(1,min(len(core),2))) + random.sample(skills_pool, k=random.randint(1,3))))\n",
        "    years = random.randint(0,12)\n",
        "    exp = f'I worked as a {role} for {years} years. I have experience in ' + ', '.join(skills) + '.'\n",
        "    resume_text = f'{name}\\\\n{role}\\\\n{exp}\\\\nResponsibilities: Delivered projects.'\n",
        "    (RES/f'resume_{i}.txt').write_text(resume_text)\n",
        "print('Wrote resumes to', RES)\n",
        "\n",
        "# JDs\n",
        "jds = {\n",
        "    'JD_Data_Scientist.txt': 'Looking for a Data Scientist with Python, SQL, Machine Learning and TensorFlow or PyTorch.',\n",
        "    'JD_Backend_Developer.txt': 'Seeking Backend Developer experienced in Java, SQL, Docker, and AWS.',\n",
        "    'JD_DevOps_Engineer.txt': 'DevOps Engineer with Kubernetes, Docker, AWS, and CI/CD automation.',\n",
        "    'JD_UX_Designer.txt': 'UX Designer with Figma, user research and prototyping experience.',\n",
        "    'JD_HR_Specialist.txt': 'HR Specialist experienced in recruiting, interviewing, payroll systems.'\n",
        "}\n",
        "for fn, txt in jds.items():\n",
        "    (JDS/fn).write_text(txt)\n",
        "print('Wrote JDs to', JDS)\n",
        "\n",
        "# Policies\n",
        "policies = {\n",
        "    'policy_1.txt': 'Equal Opportunity Policy: assess candidates on skills and experience.',\n",
        "    'policy_2.txt': 'Data Privacy Policy: Candidate personal data must be handled per local laws. Do not expose PII.',\n",
        "    'policy_3.txt': 'Promotion Eligibility: Minimum 2 years in role and demonstrable impact.',\n",
        "    'policy_4.txt': 'Interview Feedback Policy: notes must be factual.'\n",
        "}\n",
        "for fn, txt in policies.items():\n",
        "    (POL/fn).write_text(txt)\n",
        "print('Wrote policies to', POL)\n",
        "\n",
        "# Save config\n",
        "config = {'resumes_dir': str(RES), 'jds_dir': str(JDS), 'policies_dir': str(POL), 'attrition_csv': str(DATA/'attrition_synthetic.csv')}\n",
        "(DATA/'config.json').write_text(json.dumps(config, indent=2))\n",
        "print('Wrote config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b795e78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b795e78",
        "outputId": "71f3eb6d-651e-4eca-ca24-5c3dd8eac085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus size: 89\n",
            "Creating OpenAI embeddings with text-embedding-3-small\n",
            "Saved OpenAI index to /content/hr_poc_openai/models/doc_index_openai.joblib\n"
          ]
        }
      ],
      "source": [
        "# Build document index (preferred: OpenAI embeddings via new client API).\n",
        "import os, joblib, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "JDS = DATA / 'jds'\n",
        "POL = DATA / 'policy_docs'\n",
        "MODELS = BASE / 'models'\n",
        "MODELS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Gather corpus\n",
        "corpus = []\n",
        "meta = []\n",
        "for p in sorted(RES.glob('*.txt')):\n",
        "    corpus.append(p.read_text()); meta.append({'source':str(p),'type':'resume'})\n",
        "for p in sorted(JDS.glob('*.txt')):\n",
        "    corpus.append(p.read_text()); meta.append({'source':str(p),'type':'jd'})\n",
        "for p in sorted(POL.glob('*.txt')):\n",
        "    corpus.append(p.read_text()); meta.append({'source':str(p),'type':'policy'})\n",
        "print('Corpus size:', len(corpus))\n",
        "\n",
        "use_openai = bool(os.environ.get('OPENAI_API_KEY'))\n",
        "use_embeddings = False\n",
        "\n",
        "if use_openai:\n",
        "    try:\n",
        "        # Modern OpenAI client usage\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "        emb_model = 'text-embedding-3-small'\n",
        "        print('Creating OpenAI embeddings with', emb_model)\n",
        "        all_embs = []\n",
        "        B = 50\n",
        "        for i in range(0, len(corpus), B):\n",
        "            batch = corpus[i:i+B]\n",
        "            resp = client.embeddings.create(model=emb_model, input=batch)\n",
        "            # resp.data is sequence of objects with .embedding attribute\n",
        "            batch_embs = [d.embedding for d in resp.data]\n",
        "            all_embs.extend(batch_embs)\n",
        "        embs = np.array(all_embs)\n",
        "        joblib.dump({'embeddings':embs, 'docs':corpus, 'meta':meta, 'method':'openai', 'model':emb_model}, MODELS/'doc_index_openai.joblib')\n",
        "        print('Saved OpenAI index to', MODELS/'doc_index_openai.joblib')\n",
        "        use_embeddings = True\n",
        "    except Exception as e:\n",
        "        print('OpenAI embeddings failed:', e)\n",
        "        use_openai = False\n",
        "\n",
        "if (not use_embeddings):\n",
        "    try:\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        model_name = 'paraphrase-MiniLM-L3-v2'\n",
        "        print('Using SBERT model', model_name)\n",
        "        model = SentenceTransformer(model_name)\n",
        "        embs = model.encode(corpus, show_progress_bar=True)\n",
        "        joblib.dump({'embeddings':embs, 'docs':corpus, 'meta':meta, 'method':'sbert', 'model':model_name}, MODELS/'doc_index_sbert.joblib')\n",
        "        print('Saved SBERT index to', MODELS/'doc_index_sbert.joblib')\n",
        "        use_embeddings = True\n",
        "    except Exception as e:\n",
        "        print('SBERT failed:', e)\n",
        "\n",
        "if (not use_embeddings):\n",
        "    print('Falling back to TF-IDF')\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    vec = TfidfVectorizer(max_features=4000)\n",
        "    X = vec.fit_transform(corpus)\n",
        "    nn = NearestNeighbors(n_neighbors=6, metric='cosine').fit(X)\n",
        "    joblib.dump({'vectorizer':vec, 'nn':nn, 'docs':corpus, 'meta':meta, 'method':'tfidf'}, MODELS/'doc_index_tfidf.joblib')\n",
        "    print('Saved TF-IDF index to', MODELS/'doc_index_tfidf.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "95569125",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95569125",
        "outputId": "db21cc32-44cb-4ea9-b719-4ca7164622a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79\n",
            "F1: 0.0\n",
            "Saved model to /content/hr_poc_openai/models/attrition_rf.joblib\n"
          ]
        }
      ],
      "source": [
        "# Train RandomForest on attrition CSV (same as before)\n",
        "from pathlib import Path\n",
        "import pandas as pd, joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "DATA = BASE / 'data'\n",
        "MODELS = BASE / 'models'\n",
        "df = pd.read_csv(DATA/'attrition_synthetic.csv')\n",
        "df2 = pd.get_dummies(df, columns=['Gender','Education'], drop_first=True)\n",
        "X = df2.drop(columns=['Attrition']); y = df2['Attrition']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, preds))\n",
        "print('F1:', f1_score(y_test, preds))\n",
        "joblib.dump({'model':clf, 'features':list(X.columns)}, MODELS/'attrition_rf.joblib')\n",
        "print('Saved model to', MODELS/'attrition_rf.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "314e858b",
      "metadata": {
        "id": "314e858b"
      },
      "outputs": [],
      "source": [
        "# Audit logger for RAG queries\n",
        "import json, time\n",
        "from pathlib import Path\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "OUT = BASE / 'output'\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "LOG_FILE = OUT / 'audit_log.jsonl'\n",
        "def audit_log(entry: dict):\n",
        "    entry = dict(entry)\n",
        "    entry['ts'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
        "    with open(LOG_FILE, 'a') as f:\n",
        "        f.write(json.dumps(entry) + '\\n')\n",
        "    print('Logged audit entry to', LOG_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "04e4ffa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04e4ffa7",
        "outputId": "fb50f2d0-1194-482d-8d88-f0a8d0ed08bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== resume_1.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_1.txt (score=1.000)\n",
            "- resume_11.txt (score=0.909)\n",
            "- resume_21.txt (score=0.878)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "Recommendation: NO HIRE\n",
            "\n",
            "Justification: Candidate_1 has no practical experience as an ML Engineer, which is a significant drawback given the demands of the role. While they possess relevant skills in UX Design, Python, and TensorFlow, the lack of experience compared to other candidates, such as Candidate_21 with 6 years of relevant experience [DOC_2], makes them less suitable for immediate hiring.\n",
            "\n",
            "==== resume_10.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_10.txt (score=1.000)\n",
            "- resume_20.txt (score=0.880)\n",
            "- resume_50.txt (score=0.870)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "Recommendation: CONSIDER\n",
            "\n",
            "Candidate_10 has relevant experience as a Data Scientist for 6 years and is skilled in tools such as PyTorch and SQL, which are valuable for the role. However, compared to Candidate_20, who has 12 years of experience and an additional skill set including Python and Sales [DOC_1], and Candidate_50, who brings expertise in UX Design and TensorFlow alongside similar years of experience [DOC_2], Candidate_10 may not stand out as strongly. Further evaluation of the candidate's specific contributions and achievements would be beneficial.\n",
            "\n",
            "==== resume_11.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_11.txt (score=1.000)\n",
            "- resume_1.txt (score=0.909)\n",
            "- resume_51.txt (score=0.902)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "RECOMMENDATION: CONSIDER\n",
            "\n",
            "Candidate_11 has a year of experience as a ML Engineer and possesses relevant skills in TensorFlow, Data Engineering, and PyTorch, which are valuable for the role. However, compared to other candidates like Candidate_51, who has 9 years of experience and a broader skill set, the relative lack of experience may be a concern. Nevertheless, given the role and the candidate's potential, they should be considered for further evaluation. [DOC_0]\n",
            "\n",
            "==== resume_12.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_12.txt (score=1.000)\n",
            "- resume_52.txt (score=0.881)\n",
            "- resume_72.txt (score=0.870)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "Recommendation: CONSIDER\n",
            "\n",
            "Candidate_12 has 9 years of experience as a Backend Developer and possesses skills in AWS and Java, which are valuable in current tech environments. However, there are candidates like Candidate_52, who has relevant experience and a strong skill set, including Docker and Kubernetes, which may be more aligned with specific project needs [DOC_1]. Therefore, while Candidate_12 is a strong contender, further evaluation against project demands may be warranted.\n",
            "\n",
            "==== resume_13.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_13.txt (score=1.000)\n",
            "- resume_53.txt (score=0.877)\n",
            "- resume_63.txt (score=0.873)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "RECOMMENDATION: HIRE\n",
            "\n",
            "Candidate_13 has extensive experience of 12 years as a DevOps Engineer, which is significantly longer than the other candidates, and possesses a strong background in key technologies such as NLP, Computer Vision, Java, and Kubernetes. This extensive experience and technical expertise make them a suitable choice for roles requiring advanced DevOps capabilities. [DOC_0]\n",
            "\n",
            "==== resume_14.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_14.txt (score=1.000)\n",
            "- resume_24.txt (score=0.913)\n",
            "- resume_74.txt (score=0.900)\n",
            "Logged audit entry to /content/hr_poc_openai/output/audit_log.jsonl\n",
            "RECOMMENDATION: NO HIRE\n",
            "\n",
            "Candidate_14 has only one year of experience as a Product Manager and limited skillsets in React and Communication. In comparison, Candidate_24 has eleven years of experience, including both React and UX Design skills [DOC_1], which may make them a more suitable choice for the role. Additionally, Candidate_74 lacks relevant experience in Product Management with zero years in the field [DOC_2].\n"
          ]
        }
      ],
      "source": [
        "# RAG retrieval + ChatCompletion (OpenAI if present)\n",
        "import os, joblib, numpy as np\n",
        "from pathlib import Path\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "MODELS = BASE / 'models'\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "\n",
        "# Load index helper\n",
        "def load_index():\n",
        "    if (MODELS/'doc_index_openai.joblib').exists():\n",
        "        return joblib.load(MODELS/'doc_index_openai.joblib')\n",
        "    if (MODELS/'doc_index_sbert.joblib').exists():\n",
        "        return joblib.load(MODELS/'doc_index_sbert.joblib')\n",
        "    if (MODELS/'doc_index_tfidf.joblib').exists():\n",
        "        return joblib.load(MODELS/'doc_index_tfidf.joblib')\n",
        "    raise FileNotFoundError('No index found. Run the index cell.')\n",
        "\n",
        "idx = load_index()\n",
        "method = idx.get('method')\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def retrieve_topk(query_text, topk=3):\n",
        "    docs = idx['docs']; meta = idx['meta']\n",
        "    if method in ('openai','sbert'):\n",
        "        try:\n",
        "            if method == 'openai':\n",
        "                from openai import OpenAI\n",
        "                client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "                q_emb = np.array(client.embeddings.create(model=idx.get('model','text-embedding-3-small'), input=[query_text]).data[0].embedding)\n",
        "            else:\n",
        "                from sentence_transformers import SentenceTransformer\n",
        "                model = SentenceTransformer(idx.get('model','paraphrase-MiniLM-L3-v2'))\n",
        "                q_emb = model.encode([query_text])[0]\n",
        "        except Exception as e:\n",
        "            print('Query encoding failed:', e); return []\n",
        "        embs = np.array(idx['embeddings'])\n",
        "        scores = (embs @ q_emb) / ((norm(embs, axis=1) * norm(q_emb)) + 1e-8)\n",
        "        ids = list(scores.argsort()[-topk:][::-1])\n",
        "        return [{'score': float(scores[i]), 'text': docs[i], 'meta': meta[i]} for i in ids]\n",
        "    else:\n",
        "        vec = idx['vectorizer']; nn = idx['nn']\n",
        "        qv = vec.transform([query_text])\n",
        "        dists, ids = nn.kneighbors(qv, n_neighbors=topk)\n",
        "        return [{'score': float(1-d), 'text': idx['docs'][i], 'meta': idx['meta'][i]} for i,d,i in zip(ids[0], dists[0], ids[0])]\n",
        "\n",
        "def rag_answer(resume_text, topk=3):\n",
        "    retrieved = retrieve_topk(resume_text, topk=topk)\n",
        "    print('\\nTop retrieved docs:')\n",
        "    for r in retrieved:\n",
        "        print('-', Path(r['meta']['source']).name, f'(score={r[\"score\"]:.3f})')\n",
        "    sources = [r['meta']['source'] for r in retrieved]\n",
        "    context = ''\n",
        "    for i,r in enumerate(retrieved):\n",
        "        snippet = r['text'][:800]\n",
        "        context += f'[DOC_{i}] {Path(r[\"meta\"][\"source\"]).name}\\n{snippet}\\n\\n'\n",
        "    answer = None\n",
        "    if os.environ.get('OPENAI_API_KEY'):\n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "            client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "            system = 'You are an HR governance assistant. Use retrieved passages and always cite filenames like [DOC_0].'\n",
        "            prompt = f'Resume:\\n{resume_text}\\n\\nRetrieved documents:\\n{context}\\n\\nTask: Provide a 2-3 sentence recommendation (HIRE / NO HIRE / CONSIDER), justify it, and cite sources as [DOC_i].'\n",
        "            resp = client.chat.completions.create(model='gpt-4o-mini', messages=[{'role':'system','content':system},{'role':'user','content':prompt}], max_tokens=300)\n",
        "            answer = resp.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print('OpenAI chat failed:', e)\n",
        "            answer = None\n",
        "    if not answer:\n",
        "        text = resume_text.lower()\n",
        "        if 'machine learning' in text or 'data' in text or 'ml' in text:\n",
        "            rec = 'Consider for Data/ML role — strong relevant skills.'\n",
        "        else:\n",
        "            rec = 'Consider with caution — insufficient domain-specific skills.'\n",
        "        reasons = 'Recommendation based on skills and policy.'\n",
        "        cited = ', '.join([Path(s).name for s in sources])\n",
        "        answer = f'Recommendation: {rec}\\nReasons: {reasons}\\nCited sources: {cited}'\n",
        "    audit_log({'query': resume_text[:200], 'retrieved':[Path(s).name for s in sources], 'answer': answer.splitlines()[0]})\n",
        "    return answer\n",
        "\n",
        "# Demo on first 6 resumes\n",
        "for p in sorted(RES.glob('*.txt'))[:6]:\n",
        "    print('\\n====', p.name, '====')\n",
        "    rtext = p.read_text()\n",
        "    print(rag_answer(rtext, topk=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0b9de1",
      "metadata": {
        "id": "5a0b9de1"
      },
      "source": [
        "## Notes\n",
        "\n",
        "- After running the install cell, if packages were changed, **restart the Colab runtime** (Runtime → Restart runtime) and then re-run from the top. This avoids stale imports.\n",
        "- The notebook prefers OpenAI embeddings if you provided a valid key. If that fails it tries SBERT, and finally TF-IDF.\n",
        "- Embedding and Chat calls to OpenAI will consume credits — use text-embedding-3-small and limit corpus size when experimenting.\n",
        "\n",
        "Artifacts will be under `/content/hr_poc_openai/output/` and indexes in `/content/hr_poc_openai/models/`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}