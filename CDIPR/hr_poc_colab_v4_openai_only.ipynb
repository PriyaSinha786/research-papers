{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyaSinha786/research-papers/blob/main/CDIPR/hr_poc_colab_v4_openai_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6fe9755",
      "metadata": {
        "id": "c6fe9755"
      },
      "source": [
        "# HR POC v4 — OpenAI-first (no SBERT/hf-hub pin)\n",
        "\n",
        "This notebook prefers OpenAI embeddings and ChatCompletion (if you provide an API key). It **does not** install `sentence-transformers` or pin `huggingface-hub`, avoiding the package conflicts you encountered in Colab. If you do not provide a key it falls back to TF-IDF retrieval.\n",
        "\n",
        "Run cells in order. If you change packages, restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c6d64ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c6d64ba",
        "outputId": "13d3d699-ae6a-43c2-a29f-213f210f8056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed/updated minimal packages (openai, sklearn, pandas, joblib, networkx, matplotlib).\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade openai scikit-learn pandas joblib networkx matplotlib\n",
        "print('Installed/updated minimal packages (openai, sklearn, pandas, joblib, networkx, matplotlib).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57b6dcee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57b6dcee",
        "outputId": "bc18d9de-f48b-4c01-a808-1a98f0cbe606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd: /content\n",
            "files in cwd: ['.config', 'sample_data']\n",
            "openai module path: /usr/local/lib/python3.12/dist-packages/openai/__init__.py\n",
            "openai dir contains: ['Embedding', 'embeddings']\n"
          ]
        }
      ],
      "source": [
        "# Diagnostic check for openai shadowing and environment\n",
        "import os, sys\n",
        "print('cwd:', os.getcwd())\n",
        "print('files in cwd:', [f for f in os.listdir('.')][:50])\n",
        "try:\n",
        "    import openai\n",
        "    print('openai module path:', getattr(openai, '__file__', None))\n",
        "    print('openai dir contains:', [k for k in dir(openai) if 'emb' in k.lower() or 'Emb' in k])\n",
        "except Exception as e:\n",
        "    print('openai import error:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "97cf2e2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97cf2e2b",
        "outputId": "a1c0a605-7099-4520-8ae1-613608710ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key (leave blank to skip): ··········\n",
            "OPENAI_API_KEY set in environment\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "key = getpass('Enter your OpenAI API key (leave blank to skip): ')\n",
        "if key:\n",
        "    os.environ['OPENAI_API_KEY'] = key\n",
        "    print('OPENAI_API_KEY set in environment')\n",
        "else:\n",
        "    print('No key provided. Notebook will use TF-IDF fallback for retrieval.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "412270fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "412270fc",
        "outputId": "a1d2f4fc-befd-4ed0-900e-5b66b6959376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote attrition CSV to /content/hr_poc_openai/data/attrition_synthetic.csv\n",
            "Wrote resumes to /content/hr_poc_openai/data/resumes\n",
            "Wrote JDs to /content/hr_poc_openai/data/jds\n",
            "Wrote policies to /content/hr_poc_openai/data/policy_docs\n",
            "Wrote config.json\n"
          ]
        }
      ],
      "source": [
        "# Prepare data (resumes, JDs, policies, attrition CSV)\n",
        "import os, random, json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "random.seed(42)\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "JDS = DATA / 'jds'\n",
        "POL = DATA / 'policy_docs'\n",
        "MODELS = BASE / 'models'\n",
        "OUT = BASE / 'output'\n",
        "for p in [DATA, RES, JDS, POL, MODELS, OUT]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Attrition CSV\n",
        "rows = []\n",
        "for i in range(500):\n",
        "    age = random.randint(22,60)\n",
        "    monthly_income = random.randint(2000,20000)\n",
        "    job_sat = random.choice([1,2,3,4])\n",
        "    years = random.randint(0,30)\n",
        "    gender = random.choice(['Male','Female'])\n",
        "    education = random.choice([1,2,3,4,5])\n",
        "    prob_attr = 0.2\n",
        "    if age < 30 and job_sat <= 2 and years < 3:\n",
        "        prob_attr = 0.6\n",
        "    attrition = 1 if random.random() < prob_attr else 0\n",
        "    rows.append([age, monthly_income, job_sat, years, gender, education, attrition])\n",
        "df = pd.DataFrame(rows, columns=['Age','MonthlyIncome','JobSatisfaction','YearsAtCompany','Gender','Education','Attrition'])\n",
        "df.to_csv(DATA/'attrition_synthetic.csv', index=False)\n",
        "print('Wrote attrition CSV to', DATA/'attrition_synthetic.csv')\n",
        "\n",
        "# Create resumes\n",
        "skills_pool = ['Python','Java','SQL','Machine Learning','Deep Learning','NLP','Computer Vision','Data Engineering','TensorFlow','PyTorch','Kubernetes','AWS','Docker','Communication','Leadership','UX Design','Figma','React','Sales','SEO','Google Analytics','Recruiting','Interviewing','Payroll','Testing']\n",
        "roles = ['Data Scientist','ML Engineer','Backend Developer','DevOps Engineer','Product Manager','QA Engineer','UX Designer','Sales Executive','Marketing Specialist','HR Specialist']\n",
        "for i in range(1,81):\n",
        "    name = f'Candidate_{i}'\n",
        "    role = roles[i % len(roles)]\n",
        "    if i % 8 == 0:\n",
        "        skills = random.sample([s for s in skills_pool if s not in ['Python','Machine Learning','SQL','TensorFlow','PyTorch']], k=random.randint(2,5))\n",
        "    else:\n",
        "        if 'Data' in role or 'ML' in role:\n",
        "            core = ['Python','SQL','Machine Learning','TensorFlow','PyTorch']\n",
        "        elif 'Backend' in role or 'DevOps' in role:\n",
        "            core = ['Java','Kubernetes','Docker','AWS','SQL']\n",
        "        elif 'Product' in role:\n",
        "            core = ['Communication','Leadership','React']\n",
        "        elif 'QA' in role:\n",
        "            core = ['Testing','Python','Java']\n",
        "        elif 'UX' in role:\n",
        "            core = ['UX Design','Figma','Communication']\n",
        "        elif 'Sales' in role or 'Marketing' in role:\n",
        "            core = ['Sales','SEO','Google Analytics','Communication']\n",
        "        elif 'HR' in role:\n",
        "            core = ['Recruiting','Interviewing','Payroll','Communication']\n",
        "        skills = list(set(random.sample(core, k=max(1,min(len(core),2))) + random.sample(skills_pool, k=random.randint(1,3))))\n",
        "    years = random.randint(0,12)\n",
        "    exp = f'I worked as a {role} for {years} years. I have experience in ' + ', '.join(skills) + '.'\n",
        "    resume_text = f'{name}\\n{role}\\n{exp}\\nResponsibilities: Delivered projects.'\n",
        "    (RES/f'resume_{i}.txt').write_text(resume_text)\n",
        "print('Wrote resumes to', RES)\n",
        "\n",
        "# JDs\n",
        "jds = {\n",
        "    'JD_Data_Scientist.txt': 'Looking for a Data Scientist with Python, SQL, Machine Learning and TensorFlow or PyTorch.',\n",
        "    'JD_Backend_Developer.txt': 'Seeking Backend Developer experienced in Java, SQL, Docker, and AWS.',\n",
        "    'JD_DevOps_Engineer.txt': 'DevOps Engineer with Kubernetes, Docker, AWS, and CI/CD automation.',\n",
        "    'JD_UX_Designer.txt': 'UX Designer with Figma, user research and prototyping experience.',\n",
        "    'JD_HR_Specialist.txt': 'HR Specialist experienced in recruiting, interviewing, payroll systems.'\n",
        "}\n",
        "for fn, txt in jds.items():\n",
        "    (JDS/fn).write_text(txt)\n",
        "print('Wrote JDs to', JDS)\n",
        "\n",
        "# Policies\n",
        "policies = {\n",
        "    'policy_1.txt': 'Equal Opportunity Policy: assess candidates on skills and experience.',\n",
        "    'policy_2.txt': 'Data Privacy Policy: Candidate personal data must be handled per local laws. Do not expose PII.',\n",
        "    'policy_3.txt': 'Promotion Eligibility: Minimum 2 years in role and demonstrable impact.',\n",
        "    'policy_4.txt': 'Interview Feedback Policy: notes must be factual.'\n",
        "}\n",
        "for fn, txt in policies.items():\n",
        "    (POL/fn).write_text(txt)\n",
        "print('Wrote policies to', POL)\n",
        "\n",
        "# Save config\n",
        "config = {'resumes_dir': str(RES), 'jds_dir': str(JDS), 'policies_dir': str(POL), 'attrition_csv': str(DATA/'attrition_synthetic.csv')}\n",
        "(DATA/'config.json').write_text(json.dumps(config, indent=2))\n",
        "print('Wrote config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "862ba5ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862ba5ea",
        "outputId": "33b2c32c-8518-45ae-deaa-e0599399b631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus size: 89\n",
            "Creating OpenAI embeddings with text-embedding-3-small\n",
            "Saved OpenAI index to /content/hr_poc_openai/models/doc_index_openai.joblib\n"
          ]
        }
      ],
      "source": [
        "# Build index: prefer OpenAI embeddings (modern client). If no key or OpenAI call fails, fall back to TF-IDF.\n",
        "import os, joblib, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "JDS = DATA / 'jds'\n",
        "POL = DATA / 'policy_docs'\n",
        "MODELS = BASE / 'models'\n",
        "MODELS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "corpus = []; meta = []\n",
        "for p in sorted(RES.glob('*.txt')): corpus.append(p.read_text()); meta.append({'source':str(p),'type':'resume'})\n",
        "for p in sorted(JDS.glob('*.txt')): corpus.append(p.read_text()); meta.append({'source':str(p),'type':'jd'})\n",
        "for p in sorted(POL.glob('*.txt')): corpus.append(p.read_text()); meta.append({'source':str(p),'type':'policy'})\n",
        "print('Corpus size:', len(corpus))\n",
        "\n",
        "use_openai = bool(os.environ.get('OPENAI_API_KEY'))\n",
        "if use_openai:\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "        emb_model = 'text-embedding-3-small'\n",
        "        print('Creating OpenAI embeddings with', emb_model)\n",
        "        all_embs = []\n",
        "        B = 50\n",
        "        for i in range(0, len(corpus), B):\n",
        "            batch = corpus[i:i+B]\n",
        "            resp = client.embeddings.create(model=emb_model, input=batch)\n",
        "            batch_embs = [d.embedding for d in resp.data]\n",
        "            all_embs.extend(batch_embs)\n",
        "        embs = np.array(all_embs)\n",
        "        joblib.dump({'embeddings':embs, 'docs':corpus, 'meta':meta, 'method':'openai', 'model':emb_model}, MODELS/'doc_index_openai.joblib')\n",
        "        print('Saved OpenAI index to', MODELS/'doc_index_openai.joblib')\n",
        "    except Exception as e:\n",
        "        print('OpenAI embeddings failed:', e)\n",
        "        use_openai = False\n",
        "\n",
        "if not use_openai:\n",
        "    print('Using TF-IDF fallback (no OpenAI key or embeddings failed)')\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    vec = TfidfVectorizer(max_features=4000)\n",
        "    X = vec.fit_transform(corpus)\n",
        "    nn = NearestNeighbors(n_neighbors=6, metric='cosine').fit(X)\n",
        "    joblib.dump({'vectorizer':vec, 'nn':nn, 'docs':corpus, 'meta':meta, 'method':'tfidf'}, MODELS/'doc_index_tfidf.joblib')\n",
        "    print('Saved TF-IDF index to', MODELS/'doc_index_tfidf.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3f2a91a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f2a91a6",
        "outputId": "3c927853-9a57-4930-b1f0-dc69930d6265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== resume_1.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_1.txt (score=1.000)\n",
            "- resume_11.txt (score=0.888)\n",
            "- resume_51.txt (score=0.871)\n",
            "\n",
            "Answer:\n",
            " Recommendation: NO HIRE. While Candidate_1 possesses valuable skills in Deep Learning and has experience with relevant technologies, their lack of professional experience as an ML Engineer (0 years) compared to other candidates with more extensive experience, such as Candidate_51 with 9 years in the field [DOC_2], makes them less competitive for this role.\n",
            "None\n",
            "\n",
            "==== resume_10.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_10.txt (score=1.000)\n",
            "- resume_30.txt (score=0.840)\n",
            "- resume_20.txt (score=0.837)\n",
            "\n",
            "Answer:\n",
            " Recommendation: CONSIDER. Candidate_10 has solid experience as a Data Scientist, with 6 years in the field and a diverse skill set that includes Docker, Figma, and PyTorch. However, other candidates, such as Candidate_30, possess more extensive experience (12 years) and a broader range of relevant tools including Machine Learning and TensorFlow, suggesting they may bring more depth to the team [DOC_0][DOC_1].\n",
            "None\n",
            "\n",
            "==== resume_11.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_11.txt (score=1.000)\n",
            "- resume_51.txt (score=0.905)\n",
            "- resume_71.txt (score=0.899)\n",
            "\n",
            "Answer:\n",
            " CONSIDER. While Candidate_11 has relevant experience as a ML Engineer and knowledge in key technologies like PyTorch and TensorFlow, their one year of experience may not match the level of expertise demonstrated by other candidates like Candidate_51 and Candidate_71, who each have nine years of experience [DOC_1] [DOC_2]. However, Candidate_11's skills in UX Design and Data Engineering could bring valuable perspectives to a team, warranting further evaluation.\n",
            "None\n",
            "\n",
            "==== resume_12.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_12.txt (score=1.000)\n",
            "- resume_22.txt (score=0.851)\n",
            "- resume_72.txt (score=0.849)\n",
            "\n",
            "Answer:\n",
            " Recommendation: HIRE\n",
            "\n",
            "Candidate_12 has extensive experience as a Backend Developer with 9 years in the field, demonstrating a strong background in relevant technologies such as AWS and Java. Their diverse experience, which also includes skills in Sales and Recruiting, indicates a well-rounded ability to contribute to team dynamics and project delivery, making them a valuable addition to the team [DOC_0].\n",
            "None\n",
            "\n",
            "==== resume_13.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_13.txt (score=1.000)\n",
            "- resume_53.txt (score=0.866)\n",
            "- resume_63.txt (score=0.858)\n",
            "\n",
            "Answer:\n",
            " RECOMMENDATION: CONSIDER\n",
            "\n",
            "Candidate_13 has extensive experience as a DevOps Engineer for 12 years, which is a significant asset for any organization. Their expertise in Java, Computer Vision, Kubernetes, and NLP aligns well with current industry demands. However, it might be beneficial to evaluate the depth of knowledge in these areas compared to other candidates such as Candidate_53, who has relevant experience with AWS and PyTorch, or Candidate_63, who presents a balance of leadership and technology skills [DOC_0][DOC_1][DOC_2].\n",
            "None\n",
            "\n",
            "==== resume_14.txt ====\n",
            "\n",
            "Top retrieved docs:\n",
            "- resume_14.txt (score=1.000)\n",
            "- resume_24.txt (score=0.901)\n",
            "- resume_74.txt (score=0.882)\n",
            "\n",
            "Answer:\n",
            " NO HIRE. While Candidate 14 has a year of experience as a Product Manager and relevant skills in React and communication, their limited experience compared to other candidates is a concern. For example, Candidate 24 has 11 years of experience and also possesses skills in UX Design, which could be more beneficial for this role [DOC_1].\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# RAG retrieval and answer (OpenAI ChatCompletion if key present, else simple template).\n",
        "import os, joblib, numpy as np\n",
        "from pathlib import Path\n",
        "BASE = Path('/content/hr_poc_openai')\n",
        "MODELS = BASE / 'models'\n",
        "DATA = BASE / 'data'\n",
        "RES = DATA / 'resumes'\n",
        "OUT = BASE / 'output'\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load index helper\n",
        "def load_index():\n",
        "    if (MODELS/'doc_index_openai.joblib').exists():\n",
        "        return joblib.load(MODELS/'doc_index_openai.joblib')\n",
        "    if (MODELS/'doc_index_tfidf.joblib').exists():\n",
        "        return joblib.load(MODELS/'doc_index_tfidf.joblib')\n",
        "    raise FileNotFoundError('No index found. Run index cell.')\n",
        "\n",
        "idx = load_index()\n",
        "method = idx.get('method')\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def retrieve_topk(query_text, topk=3):\n",
        "    docs = idx['docs']; meta = idx['meta']\n",
        "    if method == 'openai':\n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "            client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "            q_emb = np.array(client.embeddings.create(model=idx.get('model','text-embedding-3-small'), input=[query_text]).data[0].embedding)\n",
        "        except Exception as e:\n",
        "            print('Query encode failed (OpenAI):', e); return []\n",
        "        embs = np.array(idx['embeddings'])\n",
        "        scores = (embs @ q_emb) / ((norm(embs, axis=1) * norm(q_emb)) + 1e-8)\n",
        "        ids = list(scores.argsort()[-topk:][::-1])\n",
        "        return [{'score': float(scores[i]), 'text': docs[i], 'meta': meta[i]} for i in ids]\n",
        "    else:\n",
        "        vec = idx['vectorizer']; nn = idx['nn']\n",
        "        qv = vec.transform([query_text])\n",
        "        dists, ids = nn.kneighbors(qv, n_neighbors=topk)\n",
        "        return [{'score': float(1-d), 'text': idx['docs'][i], 'meta': idx['meta'][i]} for i,d,i in zip(ids[0], dists[0], ids[0])]\n",
        "\n",
        "def rag_answer(resume_text, topk=3):\n",
        "    retrieved = retrieve_topk(resume_text, topk=topk)\n",
        "    print('\\nTop retrieved docs:')\n",
        "    for r in retrieved:\n",
        "        print('-', Path(r['meta']['source']).name, f'(score={r[\"score\"]:.3f})')\n",
        "    sources = [r['meta']['source'] for r in retrieved]\n",
        "    context = ''\n",
        "    for i,r in enumerate(retrieved):\n",
        "        snippet = r['text'][:800]\n",
        "        context += f'[DOC_{i}] {Path(r[\"meta\"][\"source\"]).name}\\n{snippet}\\n\\n'\n",
        "    answer = None\n",
        "    if os.environ.get('OPENAI_API_KEY'):\n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "            client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "            system = 'You are an HR governance assistant. Use the retrieved passages and always cite filenames like [DOC_0].'\n",
        "            prompt = f'Resume:\\n{resume_text}\\n\\nRetrieved documents:\\n{context}\\n\\nTask: Provide a 2-3 sentence recommendation (HIRE / NO HIRE / CONSIDER), justify it, and cite sources as [DOC_i].'\n",
        "            resp = client.chat.completions.create(model='gpt-4o-mini', messages=[{'role':'system','content':system},{'role':'user','content':prompt}], max_tokens=300)\n",
        "            answer = resp.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print('OpenAI chat failed:', e)\n",
        "            answer = None\n",
        "    if not answer:\n",
        "        text = resume_text.lower()\n",
        "        if 'machine learning' in text or 'data' in text or 'ml' in text:\n",
        "            rec = 'Consider for Data/ML role — strong relevant skills.'\n",
        "        else:\n",
        "            rec = 'Consider with caution — insufficient domain-specific skills.'\n",
        "        reasons = 'Recommendation based on skills and policy.'\n",
        "        cited = ', '.join([Path(s).name for s in sources])\n",
        "        answer = f'Recommendation: {rec}\\nReasons: {reasons}\\nCited sources: {cited}'\n",
        "    # audit log\n",
        "    import json, time\n",
        "    log = {'query': resume_text[:200], 'retrieved':[Path(s).name for s in sources], 'answer': answer.splitlines()[0], 'ts': time.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "    (OUT/'rag_responses.json').write_text(json.dumps(log, indent=2))\n",
        "    print('\\nAnswer:\\n', answer)\n",
        "\n",
        "# Demo on first 6 resumes\n",
        "for p in sorted(RES.glob('*.txt'))[:6]:\n",
        "    print('\\n====', p.name, '====')\n",
        "    rtext = p.read_text()\n",
        "    print(rag_answer(rtext, topk=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f580e36",
      "metadata": {
        "id": "0f580e36"
      },
      "source": [
        "## Notes\n",
        "\n",
        "- This notebook avoids changing `huggingface-hub` and `sentence-transformers` to prevent dependency conflicts with Gradio/Transformers/Diffusers that may be preinstalled in Colab. It uses OpenAI embeddings if you set `OPENAI_API_KEY`, otherwise falls back to TF-IDF retrieval.\n",
        "- Running OpenAI embedding & chat calls consumes credits — use the smaller embedding model and limit corpus size if experimenting.\n",
        "- After you run the install cell, if you make any package changes, restart the runtime (Runtime → Restart runtime) before continuing.\n",
        "\n",
        "Artifacts will be under `/content/hr_poc_openai/output/` and indexes in `/content/hr_poc_openai/models/`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}